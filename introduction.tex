%%% -*-LaTeX-*-

\chapter{Introduction} 

In this chapter, we will first set the background, introduce the motivation
behind the work and outline the rest of the thesis.  

\section{Background}
% clusters
As modern computer software and its workload scaled, operating on a single
machine became infeasible. Software started evolving to run on multiple
machines, introducing challenges in managing the infrastructure and the
software capable of running on such diverse setups. These systems evolved to
become computer clusters, a set of interconnected machines grouped together to
ehance the performance and reliability of such systems. 

% containrization
With the increased diversity of infrastructure and development environments,
consistent deployment across the cluster was achieved through shipping
containers that run applications on all the infrastructure. Containerization
enables the encapsulation of applications into portable units of software.
These units share the operating systems' kernel while being isolated from one
another. Offering isolation while being lightweight, compared to virtual
machines, massively contributed to their adoption and the emergence of a flexible
and robust infrastructure. 

% container orchestration systems
Consequently, container orchestration systems like Kubernetes, Docker Swarm,
and Nomad \cite{noauthor_swarm_0100, verma_large-scale_2015,
noauthor_multi-region_nodate} became widely adopted for offering the necessary
tools to manage the infrastructure by automating the deployment, fault
tolerance, and scaling of software run in containers. These systems also handle
the scheduling of such containers on the various machines and oversee proper
resource utilization.  

% Solutions on one cluster systems
Scheduling is particularly important due to its major effect on overall cluster
performance. Researchers built systems optimizing different aspects of cluster
scheduling. To combat low server utilization and diverse users' workloads,
systems have been developed to allow diverse workloads to run on the same
cluster \cite{bhattacharya_hierarchical_2013, hindman_mesos_nodate} with
average server utilization in some data centers ranging from 10\% to 50\%
\cite{lo_heracles_2015}. Distributed scheduling in a single cluster was
introduced to overcome the limitations of centralized schedulers, further
reducing latency and improving performance on heterogenous workloads
\cite{schwarzkopf_omega_2013, boutin_apollo_2014}. 

% one cluster limitations
However, running multiple workloads on a single cluster introduces a new set of
problems like increased interference between jobs \cite{garg_workload_2017},
whereas distributed schedulers make less than optimal scheduling decisions due
to their limited visibility of cluster resources \cite{karanasos_mercury_2015,
delgado_hawk_2015}. There is also a physical limit to how much a cluster can be
scaled without significantly reducing orchestration performance
\cite{noauthor_considerations_nodate}. 

% Introducing multi cluster environments
For the reasons mentioned above, as well as the need for workload and
geographical isolation, organizations are expanding their infrastructure into
multuiple clusters \cite{noauthor_multi-cluster_nodate}. They are now equipped
with different clusters for different workloads and teams
\cite{patel_what_2022, li_lyra_2023}. For example, 50\% of Kubernetes end users
have 10+ clusters \cite{noauthor_cncf_2023, verma_large-scale_2015}, with
companies like Mercedes nearing one thousand clusters
\cite{noauthor_mercedes-benz_2023}. Airbnb segments its clusters into more than
thirty types, and orchestrates more than a hundred clusters in their
infrastructure \cite{noauthor_dynamic_nodate-1}. Moreover, multi-cluster
environments prevent vendor lock-in, allowing organizations to run their
workloads with multiple cloud providers. Although multi-cluster environments
offer lots of advantages, they come with a cost. Resource fragmentation across
the clusters reduce effeciency and may lead to underutilization
\cite{noauthor_kubernetes_nodate}. They also increase the complexitiy of
managing the infrastructure with a potentially increased cost and orchestration
overhead. For that, systems and tools has been developed to solve the
challenges multi-cluster environments present. 


\section{Motivation}

% introducing capacity loaning
Researchers at ByteDance observed that their inference cluster utilization is
usually around 40\% because of diurnal traffic patterns, and that their
training cluster is always oversubscribed. To retain the benefits of cluster
separation and reduce its cost, they introduced \textit{capacity loaning}, a
mechanism that allows a cluster to lend resources to another cluster without
losing ownership, and they built a system on top of it called Lyra. Their policy
allows the training cluster to borrow resources from the inference one, while
permitting the latter to reclaim resources dynamically. Compared to a baseline
FIFO scheduler, capacity loaning recorded a 1.39x reduction in average queueing
time and a 1.31x reduction in job completion time (JCT), proving the
effectiveness of the method in a constrained environment. \cite{li_lyra_2023}.
% Even with the paper constraints (single policy, unidirectional loaning, and a
% pair of clusters), capacity loaning has proved to be effective. 

% introducing delay scheduling 
Delay scheduling is an algorithm designed to address the conflict between
fairness and data locality in shared clusters. If a job is set to be scheduled
according to the fairness policy but the node its data is on is full, the
scheduler delays scheduling in an attempt to schedule it on that node when
it frees up. The algorithm makes several passes trying to schedule the job as
close as it can, increasing how far the job is from its data every pass to
guarantee its eventual scheduling \cite{zaharia_delay_2010}.

% Introduce the notion of the liquid computing
Liquid computing has been introduced as an architectural paradigm that extends
resource usage into multiple users, treating the underlying infrastructure as a
continuum of computatioinal resources. Under this paradigm, participating users
work together by sharing their computational resources for increased
scalability and resource utilization. The rules established for the continuum
allow users to keep the ownership of their resources while participating in the
resource sharing when needed \cite{iorio_computing_2023, noauthor_liqo_nodate}.

This thesis presents a new trading mechanism which allows clusters to trade
resources with each other through user-defined policies and rules, dictating
which performance metrics they plan to optimize and how aggresive their
strategy is. We do that by creating a continuum of resources between
participating clusters governed by the collective clusters' trading strategies.
Our method extends capacity loaning to serve multiple clusters, without strict
restrictions on workloads, while presenting a possible incentive for all
participating clusters. We utilize delay scheduling to serve as the scheduling
algorithm for the cluster, creating a solid distinction between local and
external resources.

%\hl{possible names?: capacity trading /resource trading / resource fluidity},
%we can relate to sky computing too % GO BEYOND THEIR WORK / EVEN MORE THAN
%GENERALIZATION % We plan to generalize loaning to be non-workload specific.
%Cluster schedulers will be able to communicate % with each other when needed,
%borrowing/lending, buying/selling, or negotiating resources. % or (to trade
%presources)

\section{Outline}
The rest of this thesis is organized as follows:
\setlist{nosep}
\begin{itemize}[noitemsep]
  
  \item Chapter 2 provides the related work and establishes the scope and the
    position of this work in the space of multi-cluster environments
    management.

  \item Chapter 3 describes the architecture of the trading mechanism, explores
    the design decisions and their implications, and details the implementation
    of the mechanism's simulator.  

  \item Chapter 4 evaluates the mechanism under various constraints and
    workloads, highliting the mechanism's optimal scenarios and limitations,
    and showcasing its adaptability.

  \item Chapter 5 concludes this study's findings reflecting on their broader
    impact and implications for multi-cluster environments.  

\end{itemize}
